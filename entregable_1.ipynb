{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Union, List\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import sqlalchemy as sa\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APIRequestError(Exception):\n",
    "    def __init__(self, status_code, message, function_name):\n",
    "        self.status_code = status_code\n",
    "        self.message = message\n",
    "        self.function_name = function_name\n",
    "        super().__init__(f\"HTTP error {self.status_code} occurred in {self.function_name}: {self.message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero: funcion para traer serie intradiaria en 60 min del stock que necesito\n",
    "\n",
    "def intraday_stock_serie(symbol:str, interval:str):   \n",
    "    endpoint = 'TIME_SERIES_INTRADAY'\n",
    "    adjusted=True\n",
    "    extended_hours=False\n",
    "    size = 'compact'\n",
    "    parameters_market_data = {'function':endpoint, 'symbol':symbol, 'interval':interval, 'extended_hours':extended_hours,\n",
    "            'adjusted':adjusted,'outputsize':size,'apikey':token }\n",
    "    try:\n",
    "        r = requests.get(base_url, params=parameters_market_data)\n",
    "        r.raise_for_status()  \n",
    "        data = r.json()\n",
    "        if \"Error Message\" in data:\n",
    "            error_message = data[\"Error Message\"]\n",
    "            raise APIRequestError(r.status_code, error_message, \"intraday_stock_serie\")\n",
    "        else:\n",
    "            data = data[f'Time Series ({interval})']\n",
    "            return data\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        raise APIRequestError(http_err.response.status_code, http_err, \"intraday_stock_serie\")\n",
    "    except Exception as err:\n",
    "        raise APIRequestError(500, str(err), \"intraday_stock_serie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segundo: funcion para traer noticias relacionadas a ese stock\n",
    "\n",
    "def getSentiment(\n",
    "    symbol: str,\n",
    "    topics: Union[str, List[str]]\n",
    "):\n",
    "    \n",
    "    # Convierto topics en un solo string si vino en una lista de strings\n",
    "    if isinstance(topics, list):\n",
    "        topics = ','.join(topics)\n",
    "    \n",
    "    parameters_news_sentiment_data = {\n",
    "        'function': 'NEWS_SENTIMENT',\n",
    "        'tickers': symbol,\n",
    "        'topics': topics,\n",
    "        'apikey': token\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(base_url, params=parameters_news_sentiment_data)\n",
    "        r.raise_for_status() \n",
    "        data = r.json()\n",
    "        data_feed = data['feed']\n",
    "        data_sentiment = []\n",
    "        for i in data_feed:\n",
    "            for item in i['ticker_sentiment']:\n",
    "                if item['ticker'] == symbol:\n",
    "                    # Formateo time_published \n",
    "                    time_published = datetime.strptime(i['time_published'], '%Y%m%dT%H%M%S')\n",
    "                    formatted_time_published = time_published.strftime('%Y-%m-%d %H:%M')\n",
    "                    data_sentiment.append({\n",
    "                        'ticker': item['ticker'],\n",
    "                        'time_published': formatted_time_published,\n",
    "                        'source_domain': i['source_domain'],\n",
    "                        'relevance_score': item['relevance_score'],\n",
    "                        'ticker_sentiment_label': item['ticker_sentiment_label']\n",
    "                    })\n",
    "        return data_sentiment\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        raise APIRequestError(http_err.response.status_code, http_err, \"getSentiment\")\n",
    "    except Exception as err:\n",
    "        raise APIRequestError(500, str(err), \"getSentiment\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Unifico las funciones de market data y news data en una sola \n",
    "def get_stock_data(tickers, interval, topics):\n",
    "    stock_data_frames = {}\n",
    "    # Get database connection parameters\n",
    "    DB_NAME = os.environ.get('DB_NAME')\n",
    "    DB_USER = os.environ.get('DB_USER')\n",
    "    DB_PWD = os.environ.get('DB_PWD')\n",
    "    DB_PORT = os.environ.get('DB_PORT')\n",
    "    DB_HOST = os.environ.get('DB_HOST')\n",
    "    dbschema = f'{DB_USER}'\n",
    "\n",
    "    # Create the connection engine outside the loop\n",
    "    conn = sa.create_engine(\n",
    "        f\"postgresql://{DB_USER}:{DB_PWD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\",\n",
    "        connect_args={'options': f'-csearch_path={dbschema}'}\n",
    "    )\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Traigo intraday stock data\n",
    "            intraday_data = intraday_stock_serie(ticker, interval)\n",
    "            \n",
    "            # Traigo sentiment data\n",
    "            sentiment_data = getSentiment(ticker, topics)\n",
    "            \n",
    "            # Convierto en pandas dataframe los precios de intraday stock\n",
    "            df_intraday = pd.DataFrame.from_dict(intraday_data, orient='index')\n",
    "            df_intraday.columns = ['open_price', 'high_price', 'low_price', 'close_price', 'volume']\n",
    "            df_intraday.reset_index(inplace=True)\n",
    "            df_intraday.rename(columns={'index': 'date'}, inplace=True)\n",
    "            df_intraday['date'] = pd.to_datetime(df_intraday['date'])\n",
    "            \n",
    "            intraday_table_name = f'stock_intraday_prices_{ticker}'\n",
    "            \n",
    "            #Creo tabla de precios en redshift\n",
    "            conn.execute(f\"\"\"\n",
    "                CREATE TABLE {intraday_table_name} (\n",
    "                    date TIMESTAMP,\n",
    "                    open_price FLOAT,\n",
    "                    high_price FLOAT,\n",
    "                    low_price FLOAT,\n",
    "                    close_price FLOAT,\n",
    "                    volume INT\n",
    "                )\n",
    "                DISTKEY(date);\n",
    "            \"\"\")\n",
    "    \n",
    "\n",
    "            #Voy con el dataframe de news sentiment\n",
    "            df_sentiment = pd.DataFrame(sentiment_data)\n",
    "            sentiment_table_name = f'stock_sentiment_{ticker}'\n",
    "            \n",
    "            #Creo tabla de sentiment en redshift\n",
    "            conn.execute(f\"\"\"\n",
    "            CREATE TABLE {sentiment_table_name}  (\n",
    "                ticker VARCHAR,\n",
    "                time_published TIMESTAMP,\n",
    "                source_domain VARCHAR,\n",
    "                relevance_score VARCHAR,\n",
    "                tiker_sentiment_label VARCHAR\n",
    "            );\n",
    "            \"\"\")\n",
    "\n",
    "            \n",
    "            # Guardo los df en diccionarios\n",
    "            stock_data_frames[ticker] = {\n",
    "                'intraday_data': df_intraday,\n",
    "                'sentiment_data': df_sentiment\n",
    "            }\n",
    "            \n",
    "        except APIRequestError as api_err:\n",
    "            print(f\"{api_err.function_name}: API Request Error - Status Code {api_err.status_code}: {api_err.message}\")\n",
    "            # You can handle the error based on the status code here.\n",
    "            # For example, you may choose to skip the stock if the error is not recoverable.\n",
    "            continue\n",
    "    return stock_data_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advantage api configuration parameters\n",
    "base_url = os.environ.get('BASE_URL')\n",
    "token = os.environ.get('API_TOKEN')\n",
    "tickers = ['AAPL','IBM']\n",
    "interval = '60min'\n",
    "topics = 'technology, manufacturing, financial_markets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames_by_ticker = get_stock_data(tickers, interval, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open_price</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-28 19:00:00</td>\n",
       "      <td>195.8500</td>\n",
       "      <td>195.9500</td>\n",
       "      <td>195.7800</td>\n",
       "      <td>195.9500</td>\n",
       "      <td>20654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-28 18:00:00</td>\n",
       "      <td>195.8000</td>\n",
       "      <td>195.8600</td>\n",
       "      <td>195.7200</td>\n",
       "      <td>195.8400</td>\n",
       "      <td>22108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-28 17:00:00</td>\n",
       "      <td>195.6800</td>\n",
       "      <td>195.8300</td>\n",
       "      <td>195.6200</td>\n",
       "      <td>195.7750</td>\n",
       "      <td>359879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-28 16:00:00</td>\n",
       "      <td>195.8400</td>\n",
       "      <td>195.8700</td>\n",
       "      <td>195.3000</td>\n",
       "      <td>195.6700</td>\n",
       "      <td>15958267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-28 15:00:00</td>\n",
       "      <td>195.9250</td>\n",
       "      <td>196.1500</td>\n",
       "      <td>195.4200</td>\n",
       "      <td>195.8400</td>\n",
       "      <td>8229424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-07-21 04:00:00</td>\n",
       "      <td>192.9800</td>\n",
       "      <td>193.4000</td>\n",
       "      <td>192.9800</td>\n",
       "      <td>193.1700</td>\n",
       "      <td>28633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2023-07-20 19:00:00</td>\n",
       "      <td>192.9900</td>\n",
       "      <td>193.1200</td>\n",
       "      <td>192.5500</td>\n",
       "      <td>192.9900</td>\n",
       "      <td>84071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2023-07-20 18:00:00</td>\n",
       "      <td>192.9200</td>\n",
       "      <td>193.1700</td>\n",
       "      <td>192.8000</td>\n",
       "      <td>192.9850</td>\n",
       "      <td>87339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2023-07-20 17:00:00</td>\n",
       "      <td>195.1000</td>\n",
       "      <td>195.1000</td>\n",
       "      <td>189.9220</td>\n",
       "      <td>192.9000</td>\n",
       "      <td>112415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2023-07-20 16:00:00</td>\n",
       "      <td>193.1400</td>\n",
       "      <td>197.8700</td>\n",
       "      <td>192.9100</td>\n",
       "      <td>192.9600</td>\n",
       "      <td>14176204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date open_price high_price low_price close_price    volume\n",
       "0  2023-07-28 19:00:00   195.8500   195.9500  195.7800    195.9500     20654\n",
       "1  2023-07-28 18:00:00   195.8000   195.8600  195.7200    195.8400     22108\n",
       "2  2023-07-28 17:00:00   195.6800   195.8300  195.6200    195.7750    359879\n",
       "3  2023-07-28 16:00:00   195.8400   195.8700  195.3000    195.6700  15958267\n",
       "4  2023-07-28 15:00:00   195.9250   196.1500  195.4200    195.8400   8229424\n",
       "..                 ...        ...        ...       ...         ...       ...\n",
       "95 2023-07-21 04:00:00   192.9800   193.4000  192.9800    193.1700     28633\n",
       "96 2023-07-20 19:00:00   192.9900   193.1200  192.5500    192.9900     84071\n",
       "97 2023-07-20 18:00:00   192.9200   193.1700  192.8000    192.9850     87339\n",
       "98 2023-07-20 17:00:00   195.1000   195.1000  189.9220    192.9000    112415\n",
       "99 2023-07-20 16:00:00   193.1400   197.8700  192.9100    192.9600  14176204\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames_by_ticker['AAPL']['intraday_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7546de2d5b66e6bb4051f93f462cf1f21acc5c70ac66712f7c9fa60f386dd80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
